テンソル： 数値データが格納されるコンテナのようなもので、Numpy配列でよく表される
           次元(dimension)は軸(axis)と呼ばれる
    ・スカラー(0次元テンソル):Numpyの数値を1つしか格納していないテンソル ndim=0 np.array(10)
    ・ベクトル(1次元テンソル):Numpyの1次元配列 np.array([1,2,3])
    ・行列(2次元テンソル):    Numpyの2次元配列(行列) np.array([1,2,3],
                                                        [4,5,6])

    データテンソルの例
    ・ベクトルデータ              ：形状が(samples, features)の2次元テンソル
    ・時系列,シーケンス(系列)データ：形状が(samples, timesteps, features)の3次元テンソル
    ・画像                        ：形状が(samples, height, width, channels)の4次元テンソル
    ・動画                        ：形状が(samples, frames, height, width, channels)の5次元テンソル

        ベクトルデータは、最も一般的なデータで、サンプル軸と特徴軸の2次元 (例：人の年齢,住所,収入などの表データ)
        時系列データは、時間が重要となるので3軸目に時間軸を追加し、データはサンプル軸と特徴軸 (例：株価のデータ)
        画像データは、幅・高さ・色深度の3つの次元で表され、4次元目はカラーチャネルで1か3


一般的流れ
1. モデルの構築: ニューラルネットワークの構成、活性化関数、損失関数などを設定
2. 順伝播: 入力データから出力データまでの計算
3. 損失関数の計算: 交差エントロピー誤差などを用いて、予測と真の分布の差異を計算
4. 勾配降下法によるパラメータ更新: 損失関数を最小化する方向にパラメータを更新 ミニバッチ確率的勾配降下法などのオプティマイザ
5. 2～4を繰り返す: 損失関数が収束するまで学習を継続


・損失関数(目的関数)：訓練中の予測結果と正解との誤差を計算する数式
    回帰
    ・平均二乗誤差(Mean Square Error, MSE)
    分類
    ・交差エントロピー誤差(cross entropy error)：エントロピーとは「分布の類似度を表す指標」で正解に近いほど0に近づく

・最適化アルゴリズム(Optimizer):
    1. バッチ勾配降下法(batch): 全ての学習セットのサンプル
    2. 確率的勾配降下法(Stochastic Gradient Descent, SGD): 無作為に1つのサンプル
    3. ミニバッチ確率的勾配降下法(mini-batch): 無作為にB個のサンプル(Bはバッチサイズと呼ばれるハイパーパラメータ、慣習的に32,64,128,256,512...が使われる)
    4. モーメンタム(momentum): 勾配の移動平均をとり、SGDの振動(momentum)を抑える
    5. RMSProp: モーメンタムと同じ目的で、勾配の大きさに応じて振動方向の学習率を調整してSGDの振動を抑える
    6. Adam(Adaptive moment estimation): 4のモーメンタムと5のRMSPropの良いとこどり。 移動平均と振動方向の学習率調整でSGDの振動を抑制